{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Super resolution.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hariharan-jayakumar/superres/blob/master/Super_resolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xv0lEqzYbzs",
        "colab_type": "code",
        "outputId": "1112c1a5-8a45-4245-d70f-de6a10bff705",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaIJUbfGKvSk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9677e011-c611-465e-ac0f-cf9a5afa690b"
      },
      "source": [
        "cd /content/drive/My Drive/Projects/superres"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Projects/superres\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfsWzyz7VDoH",
        "colab_type": "code",
        "outputId": "0d383a76-222b-4874-ef56-b2ac13998896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install -U -r requirements.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pillow>=5.0.0 (from -r requirements.txt (line 1))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/41/db6dec65ddbc176a59b89485e8cc136a433ed9c6397b6bfe2cd38412051e/Pillow-6.1.0-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 6.3MB/s \n",
            "\u001b[?25hRequirement already up-to-date: tensorflow>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.14.0)\n",
            "Collecting wandb>=0.8.0 (from -r requirements.txt (line 3))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/9a/35c846af421716ce15a2391f37879f343e03a5c706f8075b9f9dfeb7ce1c/wandb-0.8.5-py2.py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 42.3MB/s \n",
            "\u001b[?25hRequirement already up-to-date: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (1.16.4)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->-r requirements.txt (line 2)) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->-r requirements.txt (line 2)) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->-r requirements.txt (line 2)) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->-r requirements.txt (line 2)) (1.14.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->-r requirements.txt (line 2)) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->-r requirements.txt (line 2)) (1.14.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->-r requirements.txt (line 2)) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->-r requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->-r requirements.txt (line 2)) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->-r requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->-r requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->-r requirements.txt (line 2)) (0.33.4)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->-r requirements.txt (line 2)) (1.1.0)\n",
            "Collecting GitPython>=1.0.0 (from wandb>=0.8.0->-r requirements.txt (line 3))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/e5/fafe827507644c32d6dc553a1c435cdf882e0c28918a5bab29f7fbebfb70/GitPython-2.1.11-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 44.4MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=0.4.0 (from wandb>=0.8.0->-r requirements.txt (line 3))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/38/7f691570ed9e85479dbe4e0959ae223d364693708ba6d293d850b657f1a0/sentry_sdk-0.10.2-py2.py3-none-any.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 24.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb>=0.8.0->-r requirements.txt (line 3)) (7.352.0)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb>=0.8.0->-r requirements.txt (line 3)) (2.21.0)\n",
            "Collecting subprocess32>=3.5.3 (from wandb>=0.8.0->-r requirements.txt (line 3))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 22.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb>=0.8.0->-r requirements.txt (line 3)) (7.0)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb>=0.8.0->-r requirements.txt (line 3))\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting watchdog>=0.8.3 (from wandb>=0.8.0->-r requirements.txt (line 3))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/e3/5a55d48a29300160779f0a0d2776d17c1b762a2039b36de528b093b87d5b/watchdog-0.9.0.tar.gz (85kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 27.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb>=0.8.0->-r requirements.txt (line 3)) (5.4.8)\n",
            "Collecting gql>=0.1.0 (from wandb>=0.8.0->-r requirements.txt (line 3))\n",
            "  Downloading https://files.pythonhosted.org/packages/aa/9c/2933b7791210e00f5c26a6243198cc03af9132c29cf85e4c22cb007f171e/gql-0.1.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: backports.tempfile>=1.0 in /usr/local/lib/python3.6/dist-packages (from wandb>=0.8.0->-r requirements.txt (line 3)) (1.0)\n",
            "Collecting shortuuid>=0.5.0 (from wandb>=0.8.0->-r requirements.txt (line 3))\n",
            "  Downloading https://files.pythonhosted.org/packages/80/d7/2bfc9332e68d3e15ea97b9b1588b3899ad565120253d3fd71c8f7f13b4fe/shortuuid-0.5.0.tar.gz\n",
            "Collecting python-dateutil>=2.6.1 (from wandb>=0.8.0->-r requirements.txt (line 3))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 40.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow>=1.13.1->-r requirements.txt (line 2)) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow>=1.13.1->-r requirements.txt (line 2)) (0.15.4)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow>=1.13.1->-r requirements.txt (line 2)) (41.0.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow>=1.13.1->-r requirements.txt (line 2)) (2.8.0)\n",
            "Collecting gitdb2>=2.0.0 (from GitPython>=1.0.0->wandb>=0.8.0->-r requirements.txt (line 3))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/30/a407568aa8d8f25db817cf50121a958722f3fc5f87e3a6fba1f40c0633e3/gitdb2-2.0.5-py2.py3-none-any.whl (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 25.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: urllib3 in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb>=0.8.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb>=0.8.0->-r requirements.txt (line 3)) (2019.6.16)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb>=0.8.0->-r requirements.txt (line 3)) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb>=0.8.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from watchdog>=0.8.3->wandb>=0.8.0->-r requirements.txt (line 3)) (3.13)\n",
            "Collecting argh>=0.24.1 (from watchdog>=0.8.3->wandb>=0.8.0->-r requirements.txt (line 3))\n",
            "  Downloading https://files.pythonhosted.org/packages/06/1c/e667a7126f0b84aaa1c56844337bf0ac12445d1beb9c8a6199a7314944bf/argh-0.26.2-py2.py3-none-any.whl\n",
            "Collecting pathtools>=0.1.1 (from watchdog>=0.8.3->wandb>=0.8.0->-r requirements.txt (line 3))\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting graphql-core>=0.5.0 (from gql>=0.1.0->wandb>=0.8.0->-r requirements.txt (line 3))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/88/a4a7bf8ab66c35b146e44d77a1f9fd2c36e0ec9fb1a51581608c16deb6e3/graphql_core-2.2-py2.py3-none-any.whl (250kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 33.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: promise>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from gql>=0.1.0->wandb>=0.8.0->-r requirements.txt (line 3)) (2.2.1)\n",
            "Requirement already satisfied, skipping upgrade: backports.weakref in /usr/local/lib/python3.6/dist-packages (from backports.tempfile>=1.0->wandb>=0.8.0->-r requirements.txt (line 3)) (1.0.post1)\n",
            "Collecting smmap2>=2.0.0 (from gitdb2>=2.0.0->GitPython>=1.0.0->wandb>=0.8.0->-r requirements.txt (line 3))\n",
            "  Downloading https://files.pythonhosted.org/packages/55/d2/866d45e3a121ee15a1dc013824d58072fd5c7799c9c34d01378eb262ca8f/smmap2-2.0.5-py2.py3-none-any.whl\n",
            "Collecting rx>=1.6.0 (from graphql-core>=0.5.0->gql>=0.1.0->wandb>=0.8.0->-r requirements.txt (line 3))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/54/fbaa34bd80d3da115f70b399761c60a91bdbad7a329541558e5b1594f636/Rx-3.0.0-py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 45.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: subprocess32, watchdog, gql, shortuuid, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/1d/d0/04cfe495619be2095eb8d89a31c42adb4e42b76495bc8f784c\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/8d/65/a3247f500d675d80a01e4d2f0ee44fe99f1faef575bc2a1664\n",
            "  Building wheel for shortuuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/eb/fd/69e5177f67b505e44acbd1aedfbe44b91768ee0c4cd5636576\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built subprocess32 watchdog gql shortuuid pathtools\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pillow, smmap2, gitdb2, GitPython, sentry-sdk, subprocess32, docker-pycreds, argh, pathtools, watchdog, rx, graphql-core, gql, shortuuid, python-dateutil, wandb\n",
            "  Found existing installation: Pillow 4.3.0\n",
            "    Uninstalling Pillow-4.3.0:\n",
            "      Successfully uninstalled Pillow-4.3.0\n",
            "  Found existing installation: python-dateutil 2.5.3\n",
            "    Uninstalling python-dateutil-2.5.3:\n",
            "      Successfully uninstalled python-dateutil-2.5.3\n",
            "Successfully installed GitPython-2.1.11 argh-0.26.2 docker-pycreds-0.4.0 gitdb2-2.0.5 gql-0.1.0 graphql-core-2.2 pathtools-0.1.2 pillow-6.1.0 python-dateutil-2.8.0 rx-3.0.0 sentry-sdk-0.10.2 shortuuid-0.5.0 smmap2-2.0.5 subprocess32-3.5.4 wandb-0.8.5 watchdog-0.9.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "dateutil"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-Dkz-Tbb2pn",
        "colab_type": "code",
        "outputId": "cba8d303-cf0c-454f-fd84-bcd8bfacdf10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "!wandb login"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You can find your API keys in your browser here: https://app.wandb.ai/authorize\n",
            "Paste an API key from your profile: 25a0dd02ea9af841eb8edc8364901cbf5e142596\n",
            "Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua50QacgRrUh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "12e76a51-edea-4c10-a65e-35fde535e84a"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDSYHa3lbwNk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2024a90f-453b-4a52-abc5-e3b918c2b4e6"
      },
      "source": [
        "import random #to randomize the image order in random generator function\n",
        "import glob #to read images from file\n",
        "import subprocess #to run the LINUX command\n",
        "import os #to check if path exists\n",
        "from PIL import Image\n",
        "import numpy as np #using numpy arrays\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "import wandb #to link the code with wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "run = wandb.init(project='superres') #connects to your project\n",
        "config = run.config #the configurations for the run\n",
        "\n",
        "config.num_epochs = 50 #number of times the model will cycle through the data\n",
        "config.batch_size = 32\n",
        "#size of input image\n",
        "config.input_height = 32\n",
        "config.input_width = 32\n",
        "#size of output image\n",
        "config.output_height = 256\n",
        "config.output_width = 256\n",
        "\n",
        "#address for validation and train datasets\n",
        "val_dir = 'data/test'\n",
        "train_dir = 'data/train'\n",
        "\n",
        "# automatically get the data if it doesn't exist\n",
        "if not os.path.exists(\"data\"):\n",
        "    print(\"Downloading flower dataset...\")\n",
        "    subprocess.check_output(\n",
        "        \"mkdir data && curl https://storage.googleapis.com/wandb/flower-enhance.tar.gz | tar xzf - -C data\", shell=True)\n",
        "\n",
        "#used to limit the iterations during an epoch\n",
        "config.steps_per_epoch = len(\n",
        "    glob.glob(train_dir + \"/*-in.jpg\")) // config.batch_size\n",
        "config.val_steps_per_epoch = len(\n",
        "    glob.glob(val_dir + \"/*-in.jpg\")) // config.batch_size\n",
        "\n",
        "#it is used to return the training images following call in line 114\n",
        "def image_generator(batch_size, img_dir):\n",
        "    \"\"\"A generator that returns small images and large images.  DO NOT ALTER the validation set\"\"\"\n",
        "    #The function takes in the batch processing size and processes batch_size images at a time\n",
        "    input_filenames = glob.glob(img_dir + \"/*-in.jpg\")\n",
        "    counter = 0\n",
        "    random.shuffle(input_filenames)\n",
        "    #input files contain the list of all files\n",
        "    while True:\n",
        "        small_images = np.zeros(\n",
        "            (batch_size, config.input_width, config.input_height, 3))\n",
        "        large_images = np.zeros(\n",
        "            (batch_size, config.output_width, config.output_height, 3))\n",
        "        #allocate space for batch_size of small and large images\n",
        "        if counter+batch_size >= len(input_filenames):\n",
        "            counter = 0\n",
        "        for i in range(batch_size): #iterates through the images\n",
        "            img = input_filenames[counter + i]\n",
        "            small_images[i] = np.array(Image.open(img)) / 255.0\n",
        "            large_images[i] = np.array(\n",
        "                Image.open(img.replace(\"-in.jpg\", \"-out.jpg\"))) / 255.0\n",
        "        yield (small_images, large_images)\n",
        "        counter += batch_size\n",
        "        #this keeps producing images to the fit_generator function in batches of batch_size\n",
        "\n",
        "\n",
        "def perceptual_distance(y_true, y_pred):\n",
        "    \"\"\"Calculate perceptual distance, DO NOT ALTER\"\"\"\n",
        "    y_true *= 255\n",
        "    y_pred *= 255\n",
        "    rmean = (y_true[:, :, :, 0] + y_pred[:, :, :, 0]) / 2\n",
        "    r = y_true[:, :, :, 0] - y_pred[:, :, :, 0]\n",
        "    g = y_true[:, :, :, 1] - y_pred[:, :, :, 1]\n",
        "    b = y_true[:, :, :, 2] - y_pred[:, :, :, 2]\n",
        "\n",
        "    return K.mean(K.sqrt((((512+rmean)*r*r)/256) + 4*g*g + (((767-rmean)*b*b)/256)))\n",
        "\n",
        "\n",
        "val_generator = image_generator(config.batch_size, val_dir)\n",
        "in_sample_images, out_sample_images = next(val_generator)\n",
        "\n",
        "\n",
        "class ImageLogger(Callback):\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        preds = self.model.predict(in_sample_images)\n",
        "        in_resized = []\n",
        "        for arr in in_sample_images:\n",
        "            # Simple upsampling\n",
        "            in_resized.append(arr.repeat(8, axis=0).repeat(8, axis=1))\n",
        "        wandb.log({\n",
        "            \"examples\": [wandb.Image(np.concatenate([in_resized[i] * 255, o * 255, out_sample_images[i] * 255], axis=1)) for i, o in enumerate(preds)]\n",
        "        }, commit=False)\n",
        "\n",
        "#we are defining a sequential model\n",
        "model = Sequential()\n",
        "#first layer contains 3 nodes with filter size (3,3) and activation, padding and input shape are defined\n",
        "model.add(layers.Conv2D(128, (9, 9), activation='relu', padding='same',\n",
        "                        input_shape=(config.input_width, config.input_height, 3)))\n",
        "#we will get an output of size (config.input_width x config.input_height x 3)\n",
        "model.add(layers.UpSampling2D())\n",
        "#repeats the image and increases each dimension size by 2 => size is ((config.input_width x 2) x (config.input_height x 2) x 3)\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.UpSampling2D())\n",
        "#size is ((config.input_width x 4) x (config.input_height x 4) x 3)\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.UpSampling2D())\n",
        "model.add(layers.Conv2D(3, (3, 3), activation='relu', padding='same'))\n",
        "#size is ((config.input_width x 8) x (config.input_height x 8) x 3)\n",
        "\n",
        "# DONT ALTER metrics=[perceptual_distance]\n",
        "model.compile(optimizer='adam', loss='mse',\n",
        "              metrics=[perceptual_distance])\n",
        "#we are defining the adam optimizer to control learning rate, loss as mse and perceptual_distance as a metric\n",
        "\n",
        "\n",
        "#fit_generator is an advanced version of fit\n",
        "#image data can be augmented on the fly using functions\n",
        "#epoch is the number of times we go through the training set\n",
        "model.fit_generator(image_generator(config.batch_size, train_dir),\n",
        "                    steps_per_epoch=config.steps_per_epoch,\n",
        "                    epochs=config.num_epochs, callbacks=[\n",
        "                        ImageLogger(), WandbCallback()],\n",
        "                    validation_steps=config.val_steps_per_epoch,\n",
        "                    validation_data=val_generator)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/darkknight/superres/runs/egnfjka5\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading flower dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0718 04:55:54.172057 140530776483712 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "156/156 [==============================] - 39s 253ms/step - loss: 0.0310 - perceptual_distance: 100.3288 - val_loss: 0.0170 - val_perceptual_distance: 72.3687\n",
            "Epoch 2/50\n",
            "156/156 [==============================] - 35s 223ms/step - loss: 0.0158 - perceptual_distance: 68.2288 - val_loss: 0.0154 - val_perceptual_distance: 67.1004\n",
            "Epoch 3/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0153 - perceptual_distance: 66.7092 - val_loss: 0.0150 - val_perceptual_distance: 65.4102\n",
            "Epoch 4/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0148 - perceptual_distance: 64.6960 - val_loss: 0.0150 - val_perceptual_distance: 65.4947\n",
            "Epoch 5/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0147 - perceptual_distance: 64.3046 - val_loss: 0.0149 - val_perceptual_distance: 65.0634\n",
            "Epoch 6/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0148 - perceptual_distance: 64.7407 - val_loss: 0.0149 - val_perceptual_distance: 64.8653\n",
            "Epoch 7/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0147 - perceptual_distance: 64.0243 - val_loss: 0.0148 - val_perceptual_distance: 64.3923\n",
            "Epoch 8/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0146 - perceptual_distance: 63.7750 - val_loss: 0.0149 - val_perceptual_distance: 65.1519\n",
            "Epoch 9/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0147 - perceptual_distance: 64.4358 - val_loss: 0.0148 - val_perceptual_distance: 65.1334\n",
            "Epoch 10/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0146 - perceptual_distance: 63.5989 - val_loss: 0.0149 - val_perceptual_distance: 65.5931\n",
            "Epoch 11/50\n",
            "156/156 [==============================] - 34s 221ms/step - loss: 0.0145 - perceptual_distance: 63.1565 - val_loss: 0.0148 - val_perceptual_distance: 64.7140\n",
            "Epoch 12/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0145 - perceptual_distance: 63.2388 - val_loss: 0.0147 - val_perceptual_distance: 64.4776\n",
            "Epoch 13/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0145 - perceptual_distance: 63.4461 - val_loss: 0.0148 - val_perceptual_distance: 64.7953\n",
            "Epoch 14/50\n",
            "156/156 [==============================] - 35s 223ms/step - loss: 0.0144 - perceptual_distance: 62.9080 - val_loss: 0.0146 - val_perceptual_distance: 63.7638\n",
            "Epoch 15/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0145 - perceptual_distance: 63.2014 - val_loss: 0.0148 - val_perceptual_distance: 64.9481\n",
            "Epoch 16/50\n",
            "156/156 [==============================] - 35s 223ms/step - loss: 0.0144 - perceptual_distance: 62.8026 - val_loss: 0.0146 - val_perceptual_distance: 63.7765\n",
            "Epoch 17/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0144 - perceptual_distance: 62.9357 - val_loss: 0.0145 - val_perceptual_distance: 63.1897\n",
            "Epoch 18/50\n",
            "156/156 [==============================] - 35s 221ms/step - loss: 0.0144 - perceptual_distance: 62.7370 - val_loss: 0.0146 - val_perceptual_distance: 63.7641\n",
            "Epoch 19/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0143 - perceptual_distance: 62.6904 - val_loss: 0.0145 - val_perceptual_distance: 63.4403\n",
            "Epoch 20/50\n",
            "156/156 [==============================] - 35s 223ms/step - loss: 0.0143 - perceptual_distance: 62.6673 - val_loss: 0.0144 - val_perceptual_distance: 63.0424\n",
            "Epoch 21/50\n",
            "156/156 [==============================] - 34s 221ms/step - loss: 0.0143 - perceptual_distance: 62.6055 - val_loss: 0.0144 - val_perceptual_distance: 62.8469\n",
            "Epoch 22/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0143 - perceptual_distance: 62.5184 - val_loss: 0.0144 - val_perceptual_distance: 62.8430\n",
            "Epoch 23/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0143 - perceptual_distance: 62.4598 - val_loss: 0.0144 - val_perceptual_distance: 62.7906\n",
            "Epoch 24/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0143 - perceptual_distance: 62.4219 - val_loss: 0.0144 - val_perceptual_distance: 63.0000\n",
            "Epoch 25/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0143 - perceptual_distance: 62.3197 - val_loss: 0.0145 - val_perceptual_distance: 63.6039\n",
            "Epoch 26/50\n",
            "156/156 [==============================] - 35s 223ms/step - loss: 0.0142 - perceptual_distance: 62.2899 - val_loss: 0.0145 - val_perceptual_distance: 63.3693\n",
            "Epoch 27/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0142 - perceptual_distance: 62.2577 - val_loss: 0.0145 - val_perceptual_distance: 63.6946\n",
            "Epoch 28/50\n",
            "156/156 [==============================] - 35s 223ms/step - loss: 0.0142 - perceptual_distance: 62.1908 - val_loss: 0.0145 - val_perceptual_distance: 63.8185\n",
            "Epoch 29/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0142 - perceptual_distance: 62.1693 - val_loss: 0.0145 - val_perceptual_distance: 63.3010\n",
            "Epoch 30/50\n",
            "156/156 [==============================] - 35s 224ms/step - loss: 0.0142 - perceptual_distance: 62.1462 - val_loss: 0.0145 - val_perceptual_distance: 63.6917\n",
            "Epoch 31/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0142 - perceptual_distance: 62.0640 - val_loss: 0.0145 - val_perceptual_distance: 63.9003\n",
            "Epoch 32/50\n",
            "156/156 [==============================] - 35s 223ms/step - loss: 0.0142 - perceptual_distance: 62.0816 - val_loss: 0.0145 - val_perceptual_distance: 63.5012\n",
            "Epoch 33/50\n",
            "156/156 [==============================] - 35s 223ms/step - loss: 0.0142 - perceptual_distance: 61.9764 - val_loss: 0.0144 - val_perceptual_distance: 62.6992\n",
            "Epoch 34/50\n",
            "156/156 [==============================] - 35s 223ms/step - loss: 0.0142 - perceptual_distance: 62.0086 - val_loss: 0.0144 - val_perceptual_distance: 63.2247\n",
            "Epoch 35/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0142 - perceptual_distance: 61.9003 - val_loss: 0.0144 - val_perceptual_distance: 63.2314\n",
            "Epoch 36/50\n",
            "156/156 [==============================] - 35s 223ms/step - loss: 0.0142 - perceptual_distance: 61.8955 - val_loss: 0.0144 - val_perceptual_distance: 63.0071\n",
            "Epoch 37/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0141 - perceptual_distance: 61.8666 - val_loss: 0.0143 - val_perceptual_distance: 62.5933\n",
            "Epoch 38/50\n",
            "156/156 [==============================] - 35s 223ms/step - loss: 0.0141 - perceptual_distance: 61.8138 - val_loss: 0.0143 - val_perceptual_distance: 62.4903\n",
            "Epoch 39/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0141 - perceptual_distance: 61.8408 - val_loss: 0.0143 - val_perceptual_distance: 62.2150\n",
            "Epoch 40/50\n",
            "156/156 [==============================] - 35s 223ms/step - loss: 0.0141 - perceptual_distance: 61.7430 - val_loss: 0.0143 - val_perceptual_distance: 62.1004\n",
            "Epoch 41/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0141 - perceptual_distance: 61.7687 - val_loss: 0.0143 - val_perceptual_distance: 61.9169\n",
            "Epoch 42/50\n",
            "156/156 [==============================] - 35s 223ms/step - loss: 0.0141 - perceptual_distance: 61.7116 - val_loss: 0.0142 - val_perceptual_distance: 61.9058\n",
            "Epoch 43/50\n",
            "156/156 [==============================] - 35s 223ms/step - loss: 0.0141 - perceptual_distance: 61.7102 - val_loss: 0.0142 - val_perceptual_distance: 61.8920\n",
            "Epoch 44/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0141 - perceptual_distance: 61.6960 - val_loss: 0.0143 - val_perceptual_distance: 62.1316\n",
            "Epoch 45/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0141 - perceptual_distance: 61.6345 - val_loss: 0.0143 - val_perceptual_distance: 62.0254\n",
            "Epoch 46/50\n",
            "156/156 [==============================] - 35s 223ms/step - loss: 0.0141 - perceptual_distance: 61.6054 - val_loss: 0.0142 - val_perceptual_distance: 61.9833\n",
            "Epoch 47/50\n",
            "156/156 [==============================] - 35s 223ms/step - loss: 0.0141 - perceptual_distance: 61.5839 - val_loss: 0.0143 - val_perceptual_distance: 62.1326\n",
            "Epoch 48/50\n",
            "156/156 [==============================] - 35s 222ms/step - loss: 0.0141 - perceptual_distance: 61.5445 - val_loss: 0.0143 - val_perceptual_distance: 62.0665\n",
            "Epoch 49/50\n",
            "156/156 [==============================] - 35s 223ms/step - loss: 0.0141 - perceptual_distance: 61.5378 - val_loss: 0.0143 - val_perceptual_distance: 62.2882\n",
            "Epoch 50/50\n",
            "156/156 [==============================] - 35s 224ms/step - loss: 0.0141 - perceptual_distance: 61.7295 - val_loss: 0.0143 - val_perceptual_distance: 62.0894\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcfcb432208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNnrwAuniWf6",
        "colab_type": "text"
      },
      "source": [
        "**First Run - 84.219**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Ran their code and obtained a Validation Perceptual Distance of **84.219**\n",
        "\n",
        "**Inference:** The training loss and the validation loss are still decreasing. Hence the network can be made more complicated or it can be run for more number of epochs.\n",
        "\n",
        "**Second Run - 62.356**\n",
        "\n",
        "---\n",
        "\n",
        "Modified the architecture of the network and obtained a Validation Perceptual Distance of **62.356**\n",
        "\n",
        "**Inference:**  \n",
        "Loss, perceptual distance, val loss and val perceptual distance are still decreasing very slowly. \n",
        "\n",
        "**Third Run - 65.7166**\n",
        "\n",
        "---\n",
        "\n",
        "Tried to bypass the benchmark and train on the validation images. But the network din't perform as well as it should have. It din't overtrain. So I increase the complexity of the network to make it overfit the data.  Still it is displaying similar performance\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2njmrMkFW07e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}